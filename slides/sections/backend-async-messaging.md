# Переход на асинхронные сообщения

---

<section data-background-image="https://github.com/akamenev/docker-windows-workshop/blob/master/slides/img/backend/Slide2.PNG?raw=true">

---

На текущий момент, приложение сохраняет данные синхронно, подсоединяясь к SQL серверу. Это узкое место, которое может сильно замедлить работу приложения во время пиковых нагрузок.

Это исправим с помощью очереди сообщений, запущенной в контейнере.

Когда мы будем нажимать `Sign Up` приложение будет публиковать событие в очереди сообщений, которое затем будет обработано message handler'ом. Message handler - это .NET Framework консольное приложение, которое запущено в отдельном контейнере

---

## The save message handler

Новый компонент это простое консольное приложение. Можете ознакомиться с [его исходным кодом](https://github.com/akamenev/docker-windows-workshop/tree/master/src/SignUp.MessageHandlers.SaveProspect) - вся логика описана в Program.cs.

Это такое же .NET Framework приложение как и оригинальное, а значит вы можете использовать логику Entity Framework из монолита. Это самый простой подход к обновлению архитектуры.

---

## Соберите обработчик сообщений

Посмотрите на [Dockerfile](https://github.com/akamenev/docker-windows-workshop/blob/master/docker/backend-async-messaging/save-handler/Dockerfile) для обработчика. 

Здесь используются все теже принципы сборки и упаковки приложения в контейнере. Используется образ .NET Framework, работающий на Windows Server Core.

_Соберите образ обработчика сообщений:_

```
docker image build `
  -t dwwx/save-handler `
  -f .\docker\backend-async-messaging\save-handler\Dockerfile .
```

---

## Использование асинхронных сообщений

Посмотрите на [v4 manifest](https://github.com/akamenev/docker-windows-workshop/blob/master/app/v4.yml) - он добавляет сервисы для обработки сообщений и очередь сообщений

Используемая очередь сообщений - [NATS](https://nats.io), это высокопроизводительная in-memory очередь, которая отлично подходит для коммуникации между контейнерами

Манифест также конфигурирует веб приложение для использования сообщений - используется Dependency Injection для загрузки другой реализации обработки сообщений

---

## Обновите приложение для использования сообщений

_Обновитесь на v4:_

```
docker-compose -f .\app\v4.yml up -d
```

---

## Проверьте работу обработчика сообщений

Теперь у вас есть очередь сообщений и обработчик сообщений в контейнерах.

Обработчик сообщений пишет в логи все события, поэтому вы можете посмотреть, что происходит в данный момент.

_Посмотрите на логи обработчика сообщений:_

```
docker container logs app_signup-save-handler_1
```

> Вы должны увидеть, что обработчик подключился и ожидает.

---

## Опробуйте новое распределенное приложение

Входная точка по прежнему на порту `8020`, вы можете перейти туда или в контейнер:

```
$ip = docker container inspect `
  --format '{{ .NetworkSettings.Networks.nat.IPAddress }}' app_proxy_1

firefox "http://$ip"
```

> Теперь, когда вы отправляете данные, веб приложение публикует событие, а затем обработчик сообщений записывает данные в БД

---

## Опробуйте новую версию

Нажмите на _Sign Up!_, заполните форму и нажмите _Go!_ чтобы сохранить данные.

Пользовательский опыт не поменялся, но теперь данные сохраняются асинхронно. Вы можете убедиться в этом, посмотрев логи.

_Посмотрите логи обработчика сообщений:_

```
docker container logs app_signup-save-handler_1
```

> Вы должны увидеть, что обработчик принял и обработал сообщение

---

## Давайте проверим, что все работает

Давайте убедимся, что данные сохранены в БД

_Проверьте наличие новых данных в SQL контейнере:_

```
docker container exec app_signup-db_1 powershell `
  "Invoke-SqlCmd -Query 'SELECT * FROM Prospects' -Database SignUp"
```

---

## Все отлично

Теперь у нас есть event-driven архитектура! Не вся конечно, но в одном из критичных сценариев у нас теперь есть асинхронная обработка запросов.

Вы можете достаточно просто масштабировать приложение, добавляя новые копии обработчика сообщений, которые ожидают одно событие

Следующий обработчик сообщений сможет отправлять данные в Elasticsearch, что позволит пользователям анализировать события приложения в Kibana
